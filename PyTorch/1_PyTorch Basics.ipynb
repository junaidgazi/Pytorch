{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fad761b-22bb-4437-a268-44f431de44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3694e-38])\n",
      "tensor([4.4294e+20, 9.7951e-43, 4.8021e-01])\n",
      "tensor([[4.4740e+20, 9.7951e-43, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[[4.4972e+20, 9.7951e-43, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
      "tensor([[0.7279, 0.4015, 0.9259],\n",
      "        [0.2591, 0.0824, 0.4123],\n",
      "        [0.2400, 0.9585, 0.3113],\n",
      "        [0.8412, 0.7347, 0.6433],\n",
      "        [0.2006, 0.1402, 0.8647]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([5, 3])\n",
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n",
      "torch.Size([2])\n",
      "tensor([[0.2887, 0.1063, 0.3694],\n",
      "        [0.2612, 0.3134, 0.6149],\n",
      "        [0.5419, 0.9917, 0.3142],\n",
      "        [0.9734, 0.8611, 0.8739],\n",
      "        [0.4948, 0.7720, 0.1484]])\n",
      "tensor([0.2887, 0.2612, 0.5419, 0.9734, 0.4948])\n",
      "tensor([0.2612, 0.3134, 0.6149])\n",
      "tensor(0.3134)\n",
      "0.31338924169540405\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Everything in pytorch is based on Tensor operations.\n",
    "# A tensor can have different dimensions\n",
    "# so it can be 1d, 2d, or even 3d and higher\n",
    "\n",
    "# scalar, vector, matrix, tensor\n",
    "\n",
    "# torch.empty(size): uninitiallized\n",
    "x = torch.empty(1) # scalar\n",
    "print(x)\n",
    "x = torch.empty(3) # vector, 1D\n",
    "print(x)\n",
    "x = torch.empty(2,3) # matrix, 2D\n",
    "print(x)\n",
    "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
    "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
    "print(x)\n",
    "\n",
    "# torch.rand(size): random numbers [0, 1]\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# torch.zeros(size), fill with 0\n",
    "# torch.ones(size), fill with 1\n",
    "x = torch.zeros(5, 3)\n",
    "print(x)\n",
    "\n",
    "# check size\n",
    "print(x.size())\n",
    "\n",
    "# check data type\n",
    "print(x.dtype)\n",
    "\n",
    "# specify types, float32 default\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "# check type\n",
    "print(x.dtype)\n",
    "\n",
    "# construct from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x.size())\n",
    "\n",
    "# requires_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "# i.e. this is a variable in your model that you want to optimize\n",
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "\n",
    "# Operations\n",
    "y = torch.rand(2, 2)\n",
    "x = torch.rand(2, 2)\n",
    "\n",
    "# elementwise addition\n",
    "z = x + y\n",
    "# torch.add(x,y)\n",
    "\n",
    "# in place addition, everythin with a trailing underscore is an inplace operation\n",
    "# i.e. it will modify the variable\n",
    "# y.add_(x)\n",
    "\n",
    "# substraction\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "z = torch.div(x,y)\n",
    "\n",
    "# Slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[:, 0]) # all rows, column 0\n",
    "print(x[1, :]) # row 1, all columns\n",
    "print(x[1,1]) # element at 1, 1\n",
    "\n",
    "# Get the actual value if only 1 element in your tensor\n",
    "print(x[1,1].item())\n",
    "\n",
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "# if -1 it pytorch will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# Numpy\n",
    "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "# torch to numpy with .numpy()\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))\n",
    "\n",
    "# Carful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# numpy to torch with .from_numpy(x)\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# again be careful when modifying\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# by default all tensors are created on the CPU,\n",
    "# but you can also move them to the GPU (only if it's available )\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
    "    # move to CPU again\n",
    "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
    "    # z = z.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aaadc3-8bd2-4069-8f42-2133a5bc8343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
